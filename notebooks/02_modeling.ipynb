{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a6216002",
   "metadata": {},
   "source": [
    "cell 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "699e2e38",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Provider</th>\n",
       "      <th>inp_claims</th>\n",
       "      <th>inp_total_reimbursed</th>\n",
       "      <th>inp_mean_reimbursed</th>\n",
       "      <th>inp_max_reimbursed</th>\n",
       "      <th>inp_mean_deductible</th>\n",
       "      <th>inp_mean_los</th>\n",
       "      <th>inp_unique_bene</th>\n",
       "      <th>outp_claims</th>\n",
       "      <th>outp_total_reimbursed</th>\n",
       "      <th>...</th>\n",
       "      <th>mean_ChronicCond_Cancer</th>\n",
       "      <th>mean_ChronicCond_ObstrPulmonary</th>\n",
       "      <th>mean_ChronicCond_Depression</th>\n",
       "      <th>mean_ChronicCond_Diabetes</th>\n",
       "      <th>mean_ChronicCond_IschemicHeart</th>\n",
       "      <th>mean_ChronicCond_Osteoporasis</th>\n",
       "      <th>mean_ChronicCond_rheumatoidarthritis</th>\n",
       "      <th>mean_ChronicCond_stroke</th>\n",
       "      <th>PotentialFraud</th>\n",
       "      <th>FraudLabel</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>PRV51001</td>\n",
       "      <td>5.0</td>\n",
       "      <td>97000.0</td>\n",
       "      <td>19400.000000</td>\n",
       "      <td>42000.0</td>\n",
       "      <td>1068.0</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>5.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>7640.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.800000</td>\n",
       "      <td>1.600000</td>\n",
       "      <td>1.200000</td>\n",
       "      <td>1.200000</td>\n",
       "      <td>1.200000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.400000</td>\n",
       "      <td>1.600000</td>\n",
       "      <td>No</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>PRV51003</td>\n",
       "      <td>62.0</td>\n",
       "      <td>573000.0</td>\n",
       "      <td>9241.935484</td>\n",
       "      <td>57000.0</td>\n",
       "      <td>1068.0</td>\n",
       "      <td>5.161290</td>\n",
       "      <td>53.0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>32670.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.887097</td>\n",
       "      <td>1.629032</td>\n",
       "      <td>1.596774</td>\n",
       "      <td>1.209677</td>\n",
       "      <td>1.112903</td>\n",
       "      <td>1.790323</td>\n",
       "      <td>1.693548</td>\n",
       "      <td>1.887097</td>\n",
       "      <td>Yes</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>PRV51004</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>149.0</td>\n",
       "      <td>52170.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>No</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>PRV51005</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1165.0</td>\n",
       "      <td>280910.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Yes</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>PRV51007</td>\n",
       "      <td>3.0</td>\n",
       "      <td>19000.0</td>\n",
       "      <td>6333.333333</td>\n",
       "      <td>10000.0</td>\n",
       "      <td>1068.0</td>\n",
       "      <td>5.333333</td>\n",
       "      <td>3.0</td>\n",
       "      <td>69.0</td>\n",
       "      <td>14710.0</td>\n",
       "      <td>...</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.333333</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.666667</td>\n",
       "      <td>1.333333</td>\n",
       "      <td>No</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 30 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Provider  inp_claims  inp_total_reimbursed  inp_mean_reimbursed  \\\n",
       "0  PRV51001         5.0               97000.0         19400.000000   \n",
       "1  PRV51003        62.0              573000.0          9241.935484   \n",
       "2  PRV51004         NaN                   NaN                  NaN   \n",
       "3  PRV51005         NaN                   NaN                  NaN   \n",
       "4  PRV51007         3.0               19000.0          6333.333333   \n",
       "\n",
       "   inp_max_reimbursed  inp_mean_deductible  inp_mean_los  inp_unique_bene  \\\n",
       "0             42000.0               1068.0      5.000000              5.0   \n",
       "1             57000.0               1068.0      5.161290             53.0   \n",
       "2                 NaN                  NaN           NaN              NaN   \n",
       "3                 NaN                  NaN           NaN              NaN   \n",
       "4             10000.0               1068.0      5.333333              3.0   \n",
       "\n",
       "   outp_claims  outp_total_reimbursed  ...  mean_ChronicCond_Cancer  \\\n",
       "0         20.0                 7640.0  ...                 1.800000   \n",
       "1         70.0                32670.0  ...                 1.887097   \n",
       "2        149.0                52170.0  ...                      NaN   \n",
       "3       1165.0               280910.0  ...                      NaN   \n",
       "4         69.0                14710.0  ...                 2.000000   \n",
       "\n",
       "   mean_ChronicCond_ObstrPulmonary  mean_ChronicCond_Depression  \\\n",
       "0                         1.600000                     1.200000   \n",
       "1                         1.629032                     1.596774   \n",
       "2                              NaN                          NaN   \n",
       "3                              NaN                          NaN   \n",
       "4                         2.000000                     1.333333   \n",
       "\n",
       "   mean_ChronicCond_Diabetes  mean_ChronicCond_IschemicHeart  \\\n",
       "0                   1.200000                        1.200000   \n",
       "1                   1.209677                        1.112903   \n",
       "2                        NaN                             NaN   \n",
       "3                        NaN                             NaN   \n",
       "4                   1.000000                        1.000000   \n",
       "\n",
       "   mean_ChronicCond_Osteoporasis  mean_ChronicCond_rheumatoidarthritis  \\\n",
       "0                       2.000000                              1.400000   \n",
       "1                       1.790323                              1.693548   \n",
       "2                            NaN                                   NaN   \n",
       "3                            NaN                                   NaN   \n",
       "4                       2.000000                              1.666667   \n",
       "\n",
       "   mean_ChronicCond_stroke  PotentialFraud  FraudLabel  \n",
       "0                 1.600000              No           0  \n",
       "1                 1.887097             Yes           1  \n",
       "2                      NaN              No           0  \n",
       "3                      NaN             Yes           1  \n",
       "4                 1.333333              No           0  \n",
       "\n",
       "[5 rows x 30 columns]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Imports & load processed data\n",
    "\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.metrics import (\n",
    "    classification_report,\n",
    "    confusion_matrix,\n",
    "    roc_auc_score,\n",
    "    average_precision_score\n",
    ")\n",
    "\n",
    "DATA_DIR = \"../data\"\n",
    "PROCESSED_DIR = os.path.join(DATA_DIR, \"processed\")\n",
    "\n",
    "train_full = pd.read_csv(os.path.join(PROCESSED_DIR, \"train_provider_features.csv\"))\n",
    "test_full  = pd.read_csv(os.path.join(PROCESSED_DIR, \"test_provider_features.csv\"))\n",
    "\n",
    "train_full.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1f9a0a4",
   "metadata": {},
   "source": [
    "cell 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "d9021f2a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dropping all-NaN columns: set()\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['../data/processed/best_model.pkl']"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# 1) Choose feature columns (everything except ID + labels)\n",
    "feature_cols = [c for c in train_full.columns \n",
    "                if c not in [\"Provider\", \"PotentialFraud\", \"FraudLabel\"]]\n",
    "\n",
    "X_train_full = train_full[feature_cols]\n",
    "y = train_full[\"FraudLabel\"]\n",
    "\n",
    "X_test_full = test_full[feature_cols].copy()\n",
    "\n",
    "# 2) Drop columns that are all-NaN in TRAIN or TEST\n",
    "cols_all_nan_train = X_train_full.columns[X_train_full.isna().all()]\n",
    "cols_all_nan_test  = X_test_full.columns[X_test_full.isna().all()]\n",
    "\n",
    "drop_cols = set(cols_all_nan_train) | set(cols_all_nan_test)\n",
    "\n",
    "print(\"Dropping all-NaN columns:\", drop_cols)\n",
    "\n",
    "feature_cols = [c for c in feature_cols if c not in drop_cols]\n",
    "X_train_full = X_train_full[feature_cols]\n",
    "X_test_full  = X_test_full[feature_cols]\n",
    "\n",
    "# 3) Compute medians from TRAIN ONLY\n",
    "medians = X_train_full.median()\n",
    "\n",
    "# 4) Fill NaNs in both train and test with TRAIN medians\n",
    "X_train_imputed = X_train_full.fillna(medians)\n",
    "X_test_imputed  = X_test_full.fillna(medians)\n",
    "\n",
    "# 5) Scale\n",
    "scaler = StandardScaler()\n",
    "X_all_scaled = scaler.fit_transform(X_train_imputed)\n",
    "\n",
    "# 6) Train/validation split on SCALED data\n",
    "indices = np.arange(len(y))\n",
    "\n",
    "X_train, X_val, y_train, y_val, idx_train, idx_val = train_test_split(\n",
    "    X_scaled,\n",
    "    y,\n",
    "    indices,\n",
    "    test_size=0.2,\n",
    "    stratify=y,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "# Save these for Notebook 3\n",
    "np.save(os.path.join(PROCESSED_DIR, \"X_val.npy\"), X_val)\n",
    "np.save(os.path.join(PROCESSED_DIR, \"y_val.npy\"), y_val)\n",
    "np.save(os.path.join(PROCESSED_DIR, \"val_indices.npy\"), idx_val)\n",
    "joblib.dump(best_model, os.path.join(PROCESSED_DIR, \"best_model.pkl\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "515616d2",
   "metadata": {},
   "source": [
    "cell 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "7e809235",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== logreg ===\n",
      "ROC-AUC: 0.9494353105035275\n",
      "PR-AUC : 0.7437851118802034\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.91      0.94       981\n",
      "           1       0.47      0.82      0.60       101\n",
      "\n",
      "    accuracy                           0.90      1082\n",
      "   macro avg       0.73      0.86      0.77      1082\n",
      "weighted avg       0.93      0.90      0.91      1082\n",
      "\n",
      "Confusion matrix:\n",
      " [[889  92]\n",
      " [ 18  83]]\n",
      "\n",
      "=== rf ===\n",
      "ROC-AUC: 0.95795359352449\n",
      "PR-AUC : 0.7497441240281424\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.98      0.97       981\n",
      "           1       0.73      0.53      0.62       101\n",
      "\n",
      "    accuracy                           0.94      1082\n",
      "   macro avg       0.84      0.76      0.79      1082\n",
      "weighted avg       0.93      0.94      0.93      1082\n",
      "\n",
      "Confusion matrix:\n",
      " [[961  20]\n",
      " [ 47  54]]\n",
      "\n",
      "=== gb ===\n",
      "ROC-AUC: 0.9642867956520422\n",
      "PR-AUC : 0.7789618517950189\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.98      0.97       981\n",
      "           1       0.75      0.60      0.67       101\n",
      "\n",
      "    accuracy                           0.94      1082\n",
      "   macro avg       0.86      0.79      0.82      1082\n",
      "weighted avg       0.94      0.94      0.94      1082\n",
      "\n",
      "Confusion matrix:\n",
      " [[961  20]\n",
      " [ 40  61]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "('gb', np.float64(0.9642867956520422), np.float64(0.7789618517950189))"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Model training and evaluation\n",
    "models = {\n",
    "    \"logreg\": LogisticRegression(max_iter=1000, class_weight=\"balanced\"),\n",
    "    \"rf\": RandomForestClassifier(\n",
    "        n_estimators=300,\n",
    "        random_state=42,\n",
    "        class_weight=\"balanced\"\n",
    "    ),\n",
    "    \"gb\": GradientBoostingClassifier(random_state=42),\n",
    "}\n",
    "\n",
    "results = {}\n",
    "\n",
    "for name, clf in models.items():\n",
    "    clf.fit(X_train, y_train)\n",
    "    y_pred = clf.predict(X_val)\n",
    "    y_proba = clf.predict_proba(X_val)[:, 1]\n",
    "\n",
    "    roc = roc_auc_score(y_val, y_proba)\n",
    "    pr  = average_precision_score(y_val, y_proba)\n",
    "\n",
    "    print(f\"\\n=== {name} ===\")\n",
    "    print(\"ROC-AUC:\", roc)\n",
    "    print(\"PR-AUC :\", pr)\n",
    "    print(classification_report(y_val, y_pred))\n",
    "    print(\"Confusion matrix:\\n\", confusion_matrix(y_val, y_pred))\n",
    "\n",
    "    results[name] = {\"model\": clf, \"roc_auc\": roc, \"pr_auc\": pr}\n",
    "\n",
    "#Select best model and save\n",
    "best_name = max(results.keys(), key=lambda k: results[k][\"pr_auc\"])\n",
    "best_model = results[best_name][\"model\"]\n",
    "best_name, results[best_name][\"roc_auc\"], results[best_name][\"pr_auc\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9566b637",
   "metadata": {},
   "source": [
    "cell 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d3da453",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1) Retrain best model on ALL training data (using the same imputed & scaled features)\n",
    "\n",
    "# Recompute scaled FULL train (we already have X_train_imputed & medians & scaler)\n",
    "X_full_imputed = X_train_imputed  # all providers in train_full\n",
    "X_full_scaled  = scaler.fit_transform(X_full_imputed)  # fit scaler on full train\n",
    "\n",
    "best_model.fit(X_full_scaled, y)\n",
    "\n",
    "# 2) Prepare TEST set: impute with same medians, scale with same scaler\n",
    "X_test_imputed = X_test_imputed  # already filled with medians earlier\n",
    "X_test_scaled  = scaler.transform(X_test_imputed)\n",
    "\n",
    "import numpy as np\n",
    "print(\"Any NaN in X_test_scaled?\", np.isnan(X_test_scaled).any())\n",
    "\n",
    "# 3) Predict probabilities\n",
    "test_proba = best_model.predict_proba(X_test_scaled)[:, 1]\n",
    "\n",
    "submission = pd.DataFrame({\n",
    "    \"Provider\": test_full[\"Provider\"],\n",
    "    \"FraudProbability\": test_proba\n",
    "})\n",
    "\n",
    "submission.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0812619",
   "metadata": {},
   "source": [
    "cell 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "3bc822dd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['../data/processed/imputer.pkl']"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import joblib\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "# Save model\n",
    "joblib.dump(best_model, \"../data/processed/best_model.pkl\")\n",
    "\n",
    "# Save validation data used for evaluation\n",
    "np.save(\"../data/processed/X_val.npy\", X_val)\n",
    "np.save(\"../data/processed/y_val.npy\", y_val)\n",
    "\n",
    "# Save scaler + imputer too if needed\n",
    "joblib.dump(scaler, \"../data/processed/scaler.pkl\")\n",
    "joblib.dump(imputer, \"../data/processed/imputer.pkl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a9bfc99",
   "metadata": {},
   "source": [
    "cell 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "14d63d96",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved: ../data/processed/provider_fraud_predictions.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/m.mohamedali/Library/Python/3.9/lib/python/site-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Rebuild feature column list (same as training)\n",
    "feature_cols = [\n",
    "    c for c in test_full.columns\n",
    "    if c not in [\"Provider\"]     # keep provider ID out of X\n",
    "]\n",
    "\n",
    "# Prepare X_test\n",
    "X_test = test_full[feature_cols].copy()\n",
    "\n",
    "# Impute missing values (same imputer used on train)\n",
    "X_test_imputed = imputer.transform(X_test)\n",
    "\n",
    "# Scale features (same scaler used on train)\n",
    "X_test_scaled = scaler.transform(X_test_imputed)\n",
    "\n",
    "# Predict fraud probability\n",
    "test_proba = best_model.predict_proba(X_test_scaled)[:, 1]\n",
    "\n",
    "# Create final dataframe\n",
    "submission = pd.DataFrame({\n",
    "    \"Provider\": test_full[\"Provider\"],\n",
    "    \"FraudProbability\": test_proba\n",
    "})\n",
    "\n",
    "# Save to CSV\n",
    "output_path = os.path.join(PROCESSED_DIR, \"provider_fraud_predictions.csv\")\n",
    "submission.to_csv(output_path, index=False)\n",
    "\n",
    "print(\"Saved:\", output_path)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
